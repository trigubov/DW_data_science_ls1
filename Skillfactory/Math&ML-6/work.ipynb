{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Загрузите стандартный датасет об алмазах из библиотеки Seaborn:\n",
    "df = sns.load_dataset('diamonds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалите часть признаков:\n",
    "\n",
    "df.drop(['depth', 'table', 'x', 'y', 'z'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Закодируйте категориальные признаки:\n",
    "\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Логарифмируйте признаки:\n",
    "\n",
    "df['carat'] = np.log(1+df['carat'])\n",
    "df['price'] = np.log(1+df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определите целевую переменную и предикторы:\n",
    "\n",
    "X = df.drop(columns=\"price\")\n",
    "y = df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 800 candidates, totalling 4000 fits\n",
      "{'alpha': 0.001, 'eta0': 0.001, 'l1_ratio': 0.0, 'learning_rate': 'constant', 'loss': 'epsilon_insensitive', 'penalty': 'elasticnet'}\n",
      "0.0436248760056415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Разделите выборку на обучающую и тестовую (объём тестовой возьмите равным 0.33), значение random_state должно быть равно 42.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Теперь реализуйте алгоритм линейной регрессии со стохастическим градиентным спуском (класс SGDRegressor). Отберите с помощью GridSearchCV оптимальные параметры по следующей сетке:\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "params = {\n",
    "    \"loss\": [\"squared_error\", \"epsilon_insensitive\"],\n",
    "    \"penalty\": [\"elasticnet\"],\n",
    "    \"alpha\": np.logspace(-3, 3, 10),\n",
    "    \"l1_ratio\": np.linspace(0, 1, 10),\n",
    "    \"learning_rate\": [\"constant\"],\n",
    "    \"eta0\": np.logspace(-4, -1, 4)\n",
    "}\n",
    "\n",
    "lr = SGDRegressor(random_state=42)\n",
    "\n",
    "#grid_search = GridSearchCV(lr, params, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search = GridSearchCV(lr, params, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Выведем значение MSE на тестовой выборке:\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_test, grid_search.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите третий корень полинома , взяв за точку старта 0.7. Введите получившееся значение с точностью до трёх знаков после точки-разделителя.\n",
    "\n",
    "Попробуйте реализовать алгоритм с использованием Python по аналогии алгоритма градиентного спуска, изученного в предыдущем модуле."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.629\n"
     ]
    }
   ],
   "source": [
    "#x = 0.7\n",
    "x = 0.629\n",
    "fx = 6*x**5 - 5*x**4 - 4*x**3 + 3*x**2\n",
    "fx_pr = 30*x**4 - 20*x**3 - 12*x**2 + 6*x\n",
    "\n",
    "print(round(x - fx/fx_pr, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6296335078534031\n",
      "0.6286680781673306\n",
      "0.6286669787778999\n",
      "0.6286669787764609\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def func1(x):\n",
    "    return 6*x**5-5*x**4-4*x**3+3*x**2\n",
    " \n",
    "def func2(x):\n",
    "    return 30*x**4-20*x**3-12*x**2+6*x\n",
    "init_value = 0.7\n",
    "iter_count = 0\n",
    "x_curr = init_value\n",
    "epsilon = 0.000001\n",
    "f = func1(x_curr)\n",
    " \n",
    "while (abs(f) > epsilon):\n",
    "    f = func1(x_curr)\n",
    "    f_prime = func2(x_curr)\n",
    "    x_curr = x_curr - (f)/(f_prime)\n",
    "    iter_count += 1\n",
    "    print(x_curr)\n",
    "print(iter_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.695121951219512\n",
      "11.734125501243229\n",
      "7.1123493600499685\n",
      "5.365000391507974\n",
      "5.015260627016227\n",
      "5.000029000201801\n",
      "5.000000000105126\n",
      "5.000000000000001\n"
     ]
    }
   ],
   "source": [
    "def func1(x):\n",
    "    return 3*x**2 - 6*x -45\n",
    "def func2(x):\n",
    "    return 6*x - 6\n",
    "\n",
    "initial_value = 42\n",
    "iter_count = 0\n",
    "x_curr = initial_value\n",
    "epsilon = 0.0001\n",
    "f = func1(x_curr)\n",
    "\n",
    "while (abs(f) > epsilon):\n",
    "    f = func1(x_curr)\n",
    "    f_prime = func2(x_curr)\n",
    "    x_curr = x_curr - (f)/(f_prime)\n",
    "    iter_count += 1\n",
    "    print(x_curr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Или в виде функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def newtons_method(f, fprime, x0, tol=0.0001):\n",
    "    iter_count = 0\n",
    "    x_curr = x0\n",
    "    f_val = f(x_curr)\n",
    "    while (abs(f_val) > tol):\n",
    "        f_val = f(x_curr)\n",
    "        f_prime_val = fprime(x_curr)\n",
    "        x_curr = x_curr - (f_val)/(f_prime_val)\n",
    "        iter_count += 1\n",
    "    return x_curr\n",
    "\n",
    "newtons_method(f=func1, fprime=func2, x0=50, tol=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# А для поиска минимума функции нужно брать первую и вторую производную вместо функции и первой производной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### реализация scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import newton\n",
    "newton(func=func1, fprime=func2, x0=50, tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1666666807529666"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func1(x):\n",
    "    return 3*8*x**2 - 2*2*x\n",
    "def func2(x):\n",
    "    return 3*8*2*x - 2*2\n",
    "\n",
    "newton(func=func1, fprime=func2, x0=42, tol=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Квазиньютоновские методы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим функцию, которую будем оптимизировать. Вместо отдельных  и  можно взять координаты единого вектора:\n",
    "\n",
    "def func(x):\n",
    "    return x[0]**2.0 + x[1]**2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь определим градиент для функции:\n",
    "\n",
    "def grad_func(x):\n",
    "    return np.array([x[0] * 2, x[1] * 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим начальную точку:\n",
    "\n",
    "x_0 = [1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим алгоритм:\n",
    "\n",
    "result = minimize(func, x_0, method='BFGS', jac=grad_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статус оптимизации Optimization terminated successfully.\n",
      "Количество оценок: 3\n",
      "Решение: f([0. 0.]) = 0.00000\n"
     ]
    }
   ],
   "source": [
    "print('Статус оптимизации %s' % result['message'])\n",
    "print('Количество оценок: %d' % result['nfev'])\n",
    "solution = result['x']\n",
    "evaluation = func(solution)\n",
    "print('Решение: f(%s) = %.5f' % (solution, evaluation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно повторить то же самое с вариацией  L-BFGS-B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статус оптимизации CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "Количество оценок: 3\n",
      "Решение: f([0. 0.]) = 0.00000\n"
     ]
    }
   ],
   "source": [
    "# определяем нашу функцию\n",
    "def func(x):\n",
    "    return x[0]**2.0 + x[1]**2.0\n",
    " \n",
    "#  определяем градиент функции\n",
    "def grad_func(x):\n",
    "    return np.array([x[0] * 2, x[1] * 2])\n",
    " \n",
    "# определяем начальную точку\n",
    "x_0 = [1, 1]\n",
    "# реализуем алгоритм L-BFGS-B\n",
    "result = minimize(func, x_0, method='L-BFGS-B', jac=grad_func)\n",
    "# получаем результат\n",
    "print('Статус оптимизации %s' % result['message'])\n",
    "print('Количество оценок: %d' % result['nfev'])\n",
    "solution = result['x']\n",
    "evaluation = func(solution)\n",
    "print('Решение: f(%s) = %.5f' % (solution, evaluation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задания\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статус оптимизации CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "Количество оценок: 9\n",
      "Решение: f([-3.99999972  1.00000028]) = -1.00000\n"
     ]
    }
   ],
   "source": [
    "# определяем нашу функцию\n",
    "def func(x):\n",
    "    return x[0] ** 2 - x[0] * x[1] + x[1] ** 2 + 9 * x[0] - 6 * x[1] + 20\n",
    " \n",
    "#  определяем градиент функции\n",
    "def grad_func(x):\n",
    "    return np.array([2 * x[0] - x[1] + 9, -x[0] + 2 * x[1] - 6])\n",
    " \n",
    "# определяем начальную точку\n",
    "x_0 = [-400, -400]\n",
    "# реализуем алгоритм L-BFGS-B\n",
    "result = minimize(func, x_0, method='L-BFGS-B', jac=grad_func)\n",
    "# получаем результат\n",
    "print('Статус оптимизации %s' % result['message'])\n",
    "print('Количество оценок: %d' % result['nfev'])\n",
    "solution = result['x']\n",
    "evaluation = func(solution)\n",
    "print('Решение: f(%s) = %.5f' % (solution, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статус оптимизации Optimization terminated successfully.\n",
      "Количество оценок: 5\n",
      "Решение: f([1.5]) = 42.75000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trigubov\\AppData\\Local\\Temp\\ipykernel_10368\\2301919385.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('Решение: f(%s) = %.5f' % (solution, evaluation))\n"
     ]
    }
   ],
   "source": [
    "def func(x):\n",
    "    return x**2 - 3*x + 45\n",
    "\n",
    "# Теперь определим градиент для функции:\n",
    "\n",
    "def grad_func(x):\n",
    "    return 2*x - 3\n",
    "\n",
    "# Зададим начальную точку:\n",
    "\n",
    "x_0 = 10\n",
    "\n",
    "# Определим алгоритм:\n",
    "\n",
    "result = minimize(func, x_0, method='BFGS', jac=grad_func)\n",
    "\n",
    "print('Статус оптимизации %s' % result['message'])\n",
    "print('Количество оценок: %d' % result['nfev'])\n",
    "solution = result['x']\n",
    "evaluation = func(solution)\n",
    "print('Решение: f(%s) = %.5f' % (solution, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статус оптимизации CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "Количество оценок: 3\n",
      "Решение: f([1.5]) = 42.75000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trigubov\\AppData\\Local\\Temp\\ipykernel_10368\\198573344.py:18: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('Решение: f(%s) = %.5f' % (solution, evaluation))\n"
     ]
    }
   ],
   "source": [
    "def func(x):\n",
    "    return x**2 - 3*x + 45\n",
    "\n",
    "# Теперь определим градиент для функции:\n",
    "\n",
    "def grad_func(x):\n",
    "    return 2*x - 3\n",
    " \n",
    "# определяем начальную точку\n",
    "x_0 = 10\n",
    "# реализуем алгоритм L-BFGS-B\n",
    "result = minimize(func, x_0, method='L-BFGS-B', jac=grad_func)\n",
    "# получаем результат\n",
    "print('Статус оптимизации %s' % result['message'])\n",
    "print('Количество оценок: %d' % result['nfev'])\n",
    "solution = result['x']\n",
    "evaluation = func(solution)\n",
    "print('Решение: f(%s) = %.5f' % (solution, evaluation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите минимум функции , взяв за стартовую точку .\n",
    "\n",
    "Какой алгоритм сошелся быстрее?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статус оптимизации Optimization terminated successfully.\n",
      "Количество оценок: 37\n",
      "Решение: f([1.31617159e-02 6.65344582e-14]) = 10.00000\n"
     ]
    }
   ],
   "source": [
    "def func(x):\n",
    "    return x[0]**4 + 6*x[1]**2 + 10\n",
    "\n",
    "# Теперь определим градиент для функции:\n",
    "\n",
    "def grad_func(x):\n",
    "    return np.array([4*x[0]**3, 6*2*x[1]])\n",
    "\n",
    "# Зададим начальную точку:\n",
    "\n",
    "x_0 = [100, 100]\n",
    "\n",
    "# Определим алгоритм:\n",
    "\n",
    "result = minimize(func, x_0, method='BFGS', jac=grad_func)\n",
    "\n",
    "print('Статус оптимизации %s' % result['message'])\n",
    "print('Количество оценок: %d' % result['nfev'])\n",
    "solution = result['x']\n",
    "evaluation = func(solution)\n",
    "print('Решение: f(%s) = %.5f' % (solution, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статус оптимизации CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "Количество оценок: 52\n",
      "Решение: f([9.59831255e-03 1.89359678e-06]) = 10.00000\n"
     ]
    }
   ],
   "source": [
    "def func(x):\n",
    "    return x[0]**4 + 6*x[1]**2 + 10\n",
    "\n",
    "# Теперь определим градиент для функции:\n",
    "\n",
    "def grad_func(x):\n",
    "    return np.array([4*x[0]**3, 6*2*x[1]])\n",
    " \n",
    "# определяем начальную точку\n",
    "x_0 = [-400, -400]\n",
    "# реализуем алгоритм L-BFGS-B\n",
    "result = minimize(func, x_0, method='L-BFGS-B', jac=grad_func)\n",
    "# получаем результат\n",
    "print('Статус оптимизации %s' % result['message'])\n",
    "print('Количество оценок: %d' % result['nfev'])\n",
    "solution = result['x']\n",
    "evaluation = func(solution)\n",
    "print('Решение: f(%s) = %.5f' % (solution, evaluation))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
