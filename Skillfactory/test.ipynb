{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "string_1 = 'abc'\n",
    "string_2 = 'ABC'\n",
    "\n",
    "print(string_1 == string_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_string = 'Шалаш'\n",
    "target_string = target_string.lower()\n",
    "if target_string == target_string[::-1] :\n",
    "        result = True\n",
    "else:\n",
    "        result = False\n",
    "        \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 10\n",
    "y = 100\n",
    "z = (x % 2 == 0) and (y >= 100)\n",
    "v = (x % 2 == 0) or (y >= 100)\n",
    "w = not(x % 2 == 0) or not(y >= 100)\n",
    "z,v,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True False\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = a\n",
    "c = [1,2,3]\n",
    "print(a == b, a == c, a is b, a is c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = 'F', 7 \n",
    "\n",
    "move_is_correct = False\n",
    "if x in ['A','B','C','D','E','F','G','H'] and y in [1,2,3,4,5,6,7,8]:\n",
    "    move_is_correct = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "s = 5\n",
    "a = 10\n",
    "if a > 0:\n",
    "   s = s + a\n",
    "else:\n",
    "   s = s - a\n",
    " \n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "result = 10\n",
    "my_dict = {'key_1': 10}\n",
    "item = my_dict.pop('key_1')\n",
    "if my_dict:\n",
    "    result = result + item\n",
    "else:\n",
    "    result = result + 1\n",
    " \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['a', 'b', 'c']\n",
    "\n",
    "if 'f' in lst:\n",
    "    x = 5\n",
    "else:\n",
    "    x = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "date = '16.04.2019 15:59'\n",
    "# category = 2\n",
    "\n",
    "#date = '12.05.2019 08:42'\n",
    "# category = 1\n",
    "\n",
    "#date = '05.07.2018 20:15'\n",
    "# category = 3\n",
    "\n",
    "\n",
    "# Разделяем строку на части по пробелу и берем первую из них\n",
    "day_month_year = date.split(' ')[0]\n",
    "# Разделяем строку по символу '.' и создаем соответствующие переменные\n",
    "day, month, year = day_month_year.split('.')\n",
    "# Проверяем, что резюме обновлено в 2019 году\n",
    "#print (year)\n",
    "#print (month)\n",
    "if int(year) == 2019:\n",
    "    # Проверяем, что резюме обновлено в мае\n",
    "    if month == 5:\n",
    "        # Присваиваем 1-ую категорию\n",
    "        category = 1\n",
    "    else:\n",
    "        # Присваиваем 2-ую категорию\n",
    "        category = 2\n",
    "else:\n",
    "    # Присваиваем 3-ью категорию\n",
    "    category = 3\n",
    "    #print (day,month,year,category)\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = [1, \"2\", 3, \"4\"]\n",
    "two = (\"a\", \"b\", \"c\", \"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"tuple\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m three \u001b[39m=\u001b[39m one \u001b[39m+\u001b[39;49m two\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"tuple\") to list"
     ]
    }
   ],
   "source": [
    "three = one + two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lst = [0,1,2,3,4,5]\n",
    "my_lst = my_lst[:-1]\n",
    "my_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'qwer':'asdf',\n",
    "           'zxcv' : 'aasdas',\n",
    "           'abcd' : 'zzzz'}\n",
    "#my_dict = sorted(my_dict.keys())\n",
    "\n",
    "#my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'some'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"server\": {\n",
    "        \"host\": \"127.0.0.1\",\n",
    "        \"port\": \"22\"\n",
    "    },\n",
    "    \"configuration\": {\n",
    "        \"ssh\": {\n",
    "            \"access\": True,\n",
    "            \"login\": \"some\",\n",
    "            \"password\": \"some\"\n",
    "        },\n",
    "        \"name\": \"2491Oaaf1414\"\n",
    "    }\n",
    "}\n",
    "config['configuration']['ssh']['login']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m my_dict\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(key, value)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for key, value in my_dict.values():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PY-10.ВведениевPandas'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'PY-10. Введение в Pandas'\n",
    "\n",
    "s.replace(' ', '')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Температура: {temperature}, оставшееся время: {remaining_time}'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature = 40\n",
    "remaining_time = 12\n",
    "\n",
    "r'Температура: {temperature}, оставшееся время: {remaining_time}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '321313c2312'\n",
    "\n",
    "s.isnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x):\n",
    "    x = 1\n",
    "\n",
    "test(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Функция чтения данных\n",
    "def read_data():\n",
    "    data = open('war_peace_processed.txt', 'rt', encoding='utf-8').read()\n",
    "    data = data.split('\\n')\n",
    "    return data\n",
    "\n",
    "\n",
    "# Функция подсчёта частоты употребления слова в тексте\n",
    "def freq(target_word):  \n",
    "    new_dict = dict() \n",
    "    for i in data: # СТРОКА С ОШИБКОЙ\n",
    "        if i not in new_dict:\n",
    "            new_dict[i] = 1\n",
    "        else:\n",
    "            new_dict[i] = new_dict.get(i) + 1\n",
    "    return new_dict.get(target_word, 0)\n",
    "\n",
    "\n",
    "# Вызов функций\n",
    "data = read_data()\n",
    "freq('война')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>()>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities=['123','345','456']\n",
    "arg = '123'\n",
    "lambda    : arg if arg in cities else 0\n",
    "lambda arg: arg if arg in cities else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "z =numpy.zeros((3, 4))\n",
    "z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "3    4\n",
       "2    3\n",
       "1    2\n",
       "4    1\n",
       "Name: action, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# создаем датафрейм\n",
    "data = {'user_id': [1, 1, 2, 2, 2, 3, 3, 3, 3, 4], \n",
    "        'action': ['login', 'search', 'search', 'login', 'buy', 'buy', 'search', 'search', 'buy', 'login']}\n",
    "users = pd.DataFrame(data)\n",
    "\n",
    "users.groupby('user_id')['action'].count().sort_values(ascending=False).iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Oranges (packaged)': 114.99,\n",
       " 'Candy (Rotfront)': 280.0,\n",
       " 'Boiled sausage': 133.99,\n",
       " 'Juice J7 (orange)': 105.59,\n",
       " 'Trout (Seven Seas)': 327.99}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = {'Oranges (packaged)': 114.99, 'Candy (Rotfront)': 280.0, 'Boiled sausage': 199.99, 'Juice J7 (orange)': 119.99, 'Trout (Seven Seas)': 399.99}\n",
    "stocks = {'Boiled sausage': '33%', 'Juice J7 (orange)': '12%', 'Trout (Seven Seas)': '18%'}\n",
    "\n",
    "\n",
    "def apply_discounts(products, stocks):\n",
    "    for product in products:\n",
    "        #print (product,products[product])\n",
    "        if product in stocks:\n",
    "            p=int(stocks[product][:-1])\n",
    "            products[product]=round((products[product] * (100-p)) /100,2)\n",
    "    return products\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "apply_discounts(products,stocks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2510"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '2510%'\n",
    "int(a[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "     -------------------------------------- 636.8/636.8 kB 3.6 MB/s eta 0:00:00\n",
      "Collecting nltk>=3.1 (from textblob)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 23.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Collecting regex>=2021.8.3 (from nltk>=3.1->textblob)\n",
      "  Downloading regex-2023.6.3-cp311-cp311-win_amd64.whl (268 kB)\n",
      "     ------------------------------------- 268.0/268.0 kB 16.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\trigubov\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n",
      "Installing collected packages: regex, nltk, textblob\n",
      "Successfully installed nltk-3.8.1 regex-2023.6.3 textblob-0.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"import\" �� ���� ����७��� ��� ���譥�\n",
      "��������, �ᯮ��塞�� �ணࠬ��� ��� ������ 䠩���.\n",
      "\"nltk.download\" �� ���� ����७��� ��� ���譥�\n",
      "��������, �ᯮ��塞�� �ணࠬ��� ��� ������ 䠩���.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\trigubov/nltk_data'\n",
      "    - 'c:\\\\Users\\\\trigubov\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\trigubov\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\trigubov\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\trigubov\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n"
     ]
    },
    {
     "ename": "MissingCorpusError",
     "evalue": "\nLooks like you are missing some required data for this feature.\n\nTo download the necessary data, simply run\n\n    python -m textblob.download_corpora\n\nor use the NLTK downloader to download the missing data: http://nltk.org/data.html\nIf this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\trigubov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\textblob\\decorators.py:35\u001b[0m, in \u001b[0;36mrequires_nltk_corpus.<locals>.decorated\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     36\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\trigubov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\textblob\\tokenizers.py:57\u001b[0m, in \u001b[0;36mSentenceTokenizer.tokenize\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m'''Return a list of sentences.'''\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[39mreturn\u001b[39;00m nltk\u001b[39m.\u001b[39;49mtokenize\u001b[39m.\u001b[39;49msent_tokenize(text)\n",
      "File \u001b[1;32mc:\\Users\\trigubov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39mReturn a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39musing NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39m:param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m tokenizer \u001b[39m=\u001b[39m load(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtokenizers/punkt/\u001b[39;49m\u001b[39m{\u001b[39;49;00mlanguage\u001b[39m}\u001b[39;49;00m\u001b[39m.pickle\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m tokenizer\u001b[39m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32mc:\\Users\\trigubov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\data.py:750\u001b[0m, in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[39m# Load the resource.\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m opened_resource \u001b[39m=\u001b[39m _open(resource_url)\n\u001b[0;32m    752\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\trigubov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[39mif\u001b[39;00m protocol \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m protocol\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnltk\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 876\u001b[0m     \u001b[39mreturn\u001b[39;00m find(path_, path \u001b[39m+\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m])\u001b[39m.\u001b[39mopen()\n\u001b[0;32m    877\u001b[0m \u001b[39melif\u001b[39;00m protocol\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    878\u001b[0m     \u001b[39m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\trigubov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\trigubov/nltk_data'\n    - 'c:\\\\Users\\\\trigubov\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\nltk_data'\n    - 'c:\\\\Users\\\\trigubov\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\trigubov\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\trigubov\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMissingCorpusError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m      3\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m'''\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[39mThe titular threat of The Blob has always struck me as the ultimate movie\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39mmonster: an insatiably hungry, amoeba-like mass able to penetrate\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39martificial intelligence run rampant.\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[39m'''\u001b[39m\n\u001b[0;32m     14\u001b[0m blob \u001b[39m=\u001b[39m TextBlob(text)\n\u001b[1;32m---> 15\u001b[0m blob\u001b[39m.\u001b[39;49mtags           \u001b[39m# [('The', 'DT'), ('titular', 'JJ'),\u001b[39;00m\n\u001b[0;32m     16\u001b[0m                     \u001b[39m#  ('threat', 'NN'), ('of', 'IN'), ...]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m blob\u001b[39m.\u001b[39mnoun_phrases   \u001b[39m# WordList(['titular threat', 'blob',\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\trigubov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\textblob\\decorators.py:24\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m---> 24\u001b[0m value \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(obj)\n\u001b[0;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\trigubov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\textblob\\blob.py:499\u001b[0m, in \u001b[0;36mBaseBlob.pos_tags\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[39m\"\"\"Returns an list of tuples of the form (word, POS tag).\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \n\u001b[0;32m    490\u001b[0m \u001b[39mExample:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[39m:rtype: list of tuples\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, TextBlob):\n\u001b[1;32m--> 499\u001b[0m     \u001b[39mreturn\u001b[39;00m [val \u001b[39mfor\u001b[39;00m sublist \u001b[39min\u001b[39;00m [s\u001b[39m.\u001b[39mpos_tags \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentences] \u001b[39mfor\u001b[39;00m val \u001b[39min\u001b[39;00m sublist]\n\u001b[0;32m    500\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    501\u001b[0m     \u001b[39mreturn\u001b[39;00m [(Word(unicode(word), pos_tag\u001b[39m=\u001b[39mt), unicode(t))\n\u001b[0;32m    502\u001b[0m             \u001b[39mfor\u001b[39;00m word, t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_tagger\u001b[39m.\u001b[39mtag(\u001b[39mself\u001b[39m)\n\u001b[0;32m    503\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m PUNCTUATION_REGEX\u001b[39m.\u001b[39mmatch(unicode(t))]\n",
      "File \u001b[1;32mc:\\Users\\trigubov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\textblob\\decorators.py:24\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m---> 24\u001b[0m value \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(obj)\n\u001b[0;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\trigubov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\textblob\\blob.py:668\u001b[0m, in \u001b[0;36mTextBlob.sentences\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[39m@cached_property\u001b[39m\n\u001b[0;32m    666\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msentences\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    667\u001b[0m     \u001b[39m\"\"\"Return list of :class:`Sentence <Sentence>` objects.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 668\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_sentence_objects()\n",
      "File \u001b[1;32mc:\\Users\\trigubov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\textblob\\blob.py:712\u001b[0m, in \u001b[0;36mTextBlob._create_sentence_objects\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[39m'''Returns a list of Sentence objects from the raw text.\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    711\u001b[0m sentence_objects \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 712\u001b[0m sentences \u001b[39m=\u001b[39m sent_tokenize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw)\n\u001b[0;32m    713\u001b[0m char_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# Keeps track of character index within the blob\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences:\n\u001b[0;32m    715\u001b[0m     \u001b[39m# Compute the start and end indices of the sentence\u001b[39;00m\n\u001b[0;32m    716\u001b[0m     \u001b[39m# within the blob\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\trigubov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\textblob\\base.py:64\u001b[0m, in \u001b[0;36mBaseTokenizer.itokenize\u001b[1;34m(self, text, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mitokenize\u001b[39m(\u001b[39mself\u001b[39m, text, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     58\u001b[0m     \u001b[39m\"\"\"Return a generator that generates tokens \"on-demand\".\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[39m    .. versionadded:: 0.6.0\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[39m    :rtype: generator\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m     \u001b[39mreturn\u001b[39;00m (t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenize(text, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\trigubov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\textblob\\decorators.py:38\u001b[0m, in \u001b[0;36mrequires_nltk_corpus.<locals>.decorated\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m     37\u001b[0m     \u001b[39mprint\u001b[39m(err)\n\u001b[1;32m---> 38\u001b[0m     \u001b[39mraise\u001b[39;00m MissingCorpusError()\n",
      "\u001b[1;31mMissingCorpusError\u001b[0m: \nLooks like you are missing some required data for this feature.\n\nTo download the necessary data, simply run\n\n    python -m textblob.download_corpora\n\nor use the NLTK downloader to download the missing data: http://nltk.org/data.html\nIf this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = '''\n",
    "The titular threat of The Blob has always struck me as the ultimate movie\n",
    "monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
    "virtually any safeguard, capable of--as a doomed doctor chillingly\n",
    "describes it--\"assimilating flesh on contact.\n",
    "Snide comparisons to gelatin be damned, it's a concept with the most\n",
    "devastating of potential consequences, not unlike the grey goo scenario\n",
    "proposed by technological theorists fearful of\n",
    "artificial intelligence run rampant.\n",
    "'''\n",
    "\n",
    "blob = TextBlob(text)\n",
    "blob.tags           # [('The', 'DT'), ('titular', 'JJ'),\n",
    "                    #  ('threat', 'NN'), ('of', 'IN'), ...]\n",
    "\n",
    "blob.noun_phrases   # WordList(['titular threat', 'blob',\n",
    "                    #            'ultimate movie monster',\n",
    "                    #            'amoeba-like mass', ...])\n",
    "\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity)\n",
    "# 0.060\n",
    "# -0.341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.5.4-cp311-cp311-win_amd64.whl (12.2 MB)\n",
      "     --------------------------------------- 12.2/12.2 MB 38.6 MB/s eta 0:00:00\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.9-cp311-cp311-win_amd64.whl (18 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.7-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.8-cp311-cp311-win_amd64.whl (91 kB)\n",
      "     ---------------------------------------- 91.9/91.9 kB 5.4 MB/s eta 0:00:00\n",
      "Collecting thinc<8.2.0,>=8.1.8 (from spacy)\n",
      "  Downloading thinc-8.1.10-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.6-cp311-cp311-win_amd64.whl (478 kB)\n",
      "     ------------------------------------- 478.8/478.8 kB 31.2 MB/s eta 0:00:00\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 45.9/45.9 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting pathy>=0.10.0 (from spacy)\n",
      "  Downloading pathy-0.10.2-py3-none-any.whl (48 kB)\n",
      "     ---------------------------------------- 48.9/48.9 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy)\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "     ---------------------------------------- 56.8/56.8 kB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.10.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\trigubov\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (21.3)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     ------------------------------------- 181.6/181.6 kB 10.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\trigubov\\appdata\\roaming\\python\\python311\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.2.0,>=8.1.8->spacy)\n",
      "  Downloading blis-0.7.9-cp311-cp311-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 44.8 MB/s eta 0:00:00\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.2.0,>=8.1.8->spacy)\n",
      "  Downloading confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\trigubov\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy) (2.1.2)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, murmurhash, langcodes, catalogue, blis, typer, srsly, preshed, pathy, confection, thinc, spacy\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.2 preshed-3.0.8 smart-open-6.3.0 spacy-3.5.4 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.10 typer-0.9.0 wasabi-1.1.2\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     --------------------------------------- 12.8/12.8 MB 40.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\trigubov\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\trigubov\\appdata\\roaming\\python\\python311\\site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\trigubov\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.5.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# расскомментриуйте две следующие строки,\n",
    "# чтобы установить библиотеку и модуль\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      ", This, crappy, shit, hotel, ., Dirty, and, messy, !, \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"\"\"\n",
    "This crappy shit hotel. Dirty and messy!\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "token_list = [token for token in doc]\n",
    "\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      ", crappy, shit, hotel, ., Dirty, messy, !, \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "filtered_tokens = [token for token in doc if not token.is_stop]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Token: \\n, lemma: \\n', 'Token: crappy, lemma: crappy', 'Token: shit, lemma: shit', 'Token: hotel, lemma: hotel', 'Token: ., lemma: .', 'Token: Dirty, lemma: dirty', 'Token: messy, lemma: messy', 'Token: !, lemma: !', 'Token: \\n, lemma: \\n']\n"
     ]
    }
   ],
   "source": [
    "lemmas = [\n",
    "    f\"Token: {token}, lemma: {token.lemma_}\"\n",
    "    for token in filtered_tokens\n",
    "]\n",
    "\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.1670973 , -0.59274185,  0.04860109, -0.6340461 , -0.17828757,\n",
       "        1.0902072 , -0.46979365, -1.0955826 , -0.35339803, -1.6557747 ,\n",
       "        0.21023768,  0.14270347,  0.13925686, -0.581312  , -1.6730952 ,\n",
       "        0.08657131, -1.2436454 , -0.9404556 , -0.9658602 ,  0.21332088,\n",
       "       -0.844337  ,  1.0756023 ,  0.787624  ,  0.06133726,  0.4982633 ,\n",
       "       -0.57092893, -1.2526201 ,  0.57768977,  2.0540438 , -0.2862343 ,\n",
       "        2.1761928 , -0.8291309 ,  0.16633874, -0.23895149,  0.11658412,\n",
       "        0.43741268,  0.77331597, -1.4529148 ,  2.1690087 , -1.7467383 ,\n",
       "       -2.6259217 ,  0.7686872 ,  0.4893106 ,  0.38666064,  1.4444294 ,\n",
       "       -0.3962267 , -0.52016544, -0.71033263, -1.1795802 , -0.12289196,\n",
       "       -0.60411346,  3.0577157 , -0.67427677, -0.4281569 ,  0.101291  ,\n",
       "        0.9410871 ,  1.3480442 ,  1.047244  , -1.5026127 ,  0.28976238,\n",
       "       -0.67596304, -0.47742698,  0.35705477, -1.7194335 , -0.20577714,\n",
       "       -0.26157966,  0.22473669,  0.38361418, -0.00930265,  0.9766271 ,\n",
       "        0.88000464,  0.7573018 , -0.40776294,  0.62808275,  0.0129731 ,\n",
       "        0.33466464, -1.6630735 , -1.0801513 , -0.35258707, -0.66938347,\n",
       "       -0.4208572 , -0.6162675 ,  1.7546458 ,  0.9158631 , -0.02644356,\n",
       "        0.6824302 ,  0.6093268 , -0.07689175,  1.0972599 , -0.59969413,\n",
       "        1.3600109 ,  0.5339767 ,  1.3877926 ,  0.44784576, -0.04712489,\n",
       "        0.2702732 ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tokens[1].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentistrength\n",
      "  Downloading sentistrength-0.0.9-py3-none-any.whl (3.8 kB)\n",
      "Installing collected packages: sentistrength\n",
      "Successfully installed sentistrength-0.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install sentistrength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentistrength\n",
    "\n",
    "def get_sentiment(text):\n",
    "  sentiment = sentistrength.analyze(text)[0]\n",
    "  return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#get_sentiment(text)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sentistrength(text)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "#get_sentiment(text)\n",
    "sentistrength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Set path using setSentiStrengthPath(path) function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msentistrength\u001b[39;00m \u001b[39mimport\u001b[39;00m PySentiStr\n\u001b[0;32m      2\u001b[0m senti \u001b[39m=\u001b[39m PySentiStr()\n\u001b[1;32m----> 3\u001b[0m result \u001b[39m=\u001b[39m senti\u001b[39m.\u001b[39;49mgetSentiment(\u001b[39m'\u001b[39;49m\u001b[39mWhat a lovely day\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "File \u001b[1;32mc:\\Users\\trigubov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentistrength\\__init__.py:23\u001b[0m, in \u001b[0;36mPySentiStr.getSentiment\u001b[1;34m(self, df_text, score)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetSentiment\u001b[39m(\u001b[39mself\u001b[39m, df_text, score\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     22\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSentiStrengthLocation\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> 23\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mSet path using setSentiStrengthPath(path) function.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     25\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSentiStrengthLanguageFolder\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     26\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mSet path using setSentiStrengthLanguageFolderPath(path) function.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Set path using setSentiStrengthPath(path) function."
     ]
    }
   ],
   "source": [
    "from sentistrength import PySentiStr\n",
    "senti = PySentiStr()\n",
    "result = senti.getSentiment('What a lovely day')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Set path using setSentiStrengthPath(path) function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m senti \u001b[39m=\u001b[39m PySentiStr()\n\u001b[0;32m      3\u001b[0m str_arr \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mWhat a lovely day\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mWhat a bad day\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m result \u001b[39m=\u001b[39m senti\u001b[39m.\u001b[39;49mgetSentiment(str_arr, score\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mscale\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "File \u001b[1;32mc:\\Users\\trigubov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentistrength\\__init__.py:23\u001b[0m, in \u001b[0;36mPySentiStr.getSentiment\u001b[1;34m(self, df_text, score)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetSentiment\u001b[39m(\u001b[39mself\u001b[39m, df_text, score\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     22\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSentiStrengthLocation\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> 23\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mSet path using setSentiStrengthPath(path) function.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     25\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSentiStrengthLanguageFolder\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     26\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mSet path using setSentiStrengthLanguageFolderPath(path) function.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Set path using setSentiStrengthPath(path) function."
     ]
    }
   ],
   "source": [
    "from sentistrength import PySentiStr\n",
    "senti = PySentiStr()\n",
    "str_arr = ['What a lovely day', 'What a bad day']\n",
    "result = senti.getSentiment(str_arr, score='scale')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\trigubov\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\trigubov\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст нейтральный.\n",
      "Полярность: 0.0\n",
      "Субъективность: 0.0\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = \"no room service\"\n",
    "\n",
    "blob = TextBlob(text)\n",
    "sentiment = blob.sentiment\n",
    "\n",
    "polarity = sentiment.polarity\n",
    "subjectivity = sentiment.subjectivity\n",
    "\n",
    "if polarity > 0:\n",
    "    print(\"Текст положительно окрашен.\")\n",
    "elif polarity < 0:\n",
    "    print(\"Текст отрицательно окрашен.\")\n",
    "else:\n",
    "    print(\"Текст нейтральный.\")\n",
    "\n",
    "print(\"Полярность:\", polarity)\n",
    "print(\"Субъективность:\", subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нормализованное значение количества посетителей от 25 апреля: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Исходные данные\n",
    "min_visitors = 10\n",
    "max_visitors = 35\n",
    "april_25_visitors = 17\n",
    "\n",
    "# Разница между максимальным и минимальным значением\n",
    "diff = max_visitors - min_visitors\n",
    "\n",
    "# Создание экземпляра MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Преобразование данных и нормализация\n",
    "normalized_value = scaler.fit_transform([[april_25_visitors - min_visitors]])[0][0]\n",
    "\n",
    "# Округление до одного знака после точки-разделителя\n",
    "rounded_normalized_value = round(normalized_value, 1)\n",
    "\n",
    "print(f\"Нормализованное значение количества посетителей от 25 апреля: {rounded_normalized_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нормализованное значение количества посетителей от 25 апреля: 10.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Исходные данные\n",
    "min_visitors = 10\n",
    "max_visitors = 35\n",
    "april_25_visitors = 17\n",
    "\n",
    "# Создание экземпляра MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(min_visitors, max_visitors))\n",
    "\n",
    "# Преобразование данных и нормализация\n",
    "normalized_value = scaler.fit_transform([[april_25_visitors]])[0][0]\n",
    "\n",
    "# Округление до одного знака после точки-разделителя\n",
    "rounded_normalized_value = round(normalized_value, 1)\n",
    "\n",
    "print(f\"Нормализованное значение количества посетителей от 25 апреля: {rounded_normalized_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нормализованное значение количества посетителей от 25 апреля: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Исходные данные\n",
    "min_visitors = 10\n",
    "max_visitors = 35\n",
    "april_25_visitors = 17\n",
    "\n",
    "# Нормализация значения\n",
    "normalized_value = (april_25_visitors - min_visitors) / (max_visitors - min_visitors)\n",
    "\n",
    "# Округление до одного знака после точки-разделителя\n",
    "rounded_normalized_value = round(normalized_value, 1)\n",
    "\n",
    "print(f\"Нормализованное значение количества посетителей от 25 апреля: {rounded_normalized_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "data = [30, 40, 35, 57, 15]\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaled_data = scaler.fit_transform([[x] for x in data])\n",
    "\n",
    "normalized_value = scaled_data[2][0]  # Нормализованное значение за третий день\n",
    "rounded_value = round(normalized_value, 1)  # Округление до одного знака после точки\n",
    "\n",
    "print(rounded_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = [30, 40, 35, 57, 15]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform([[x] for x in data])\n",
    "\n",
    "normalized_value = scaled_data[2][0]  # Нормализованное значение за третий день\n",
    "rounded_value = round(normalized_value, 1)  # Округление до одного знака после точки\n",
    "\n",
    "print(rounded_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     10.0\n",
       "1     30.0\n",
       "2     50.0\n",
       "3     70.0\n",
       "4     90.0\n",
       "5    110.0\n",
       "6    130.0\n",
       "7    150.0\n",
       "8    170.0\n",
       "9    190.0\n",
       "Name: values_column, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Создаем пример датафрейма\n",
    "data = {'values_column': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Вычисляем сумму текущего значения и трех последующих строк\n",
    "df['values_column'].rolling(window=2,min_periods=1).sum()\n",
    "# Выводим полученный датафрейм\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   values_column  sum_next_5\n",
      "0             10          30\n",
      "1             20          50\n",
      "2             30          70\n",
      "3             40          90\n",
      "4             50         110\n",
      "5             60         130\n",
      "6             70         150\n",
      "7             80         170\n",
      "8             90         190\n",
      "9            100         100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Создаем пример датафрейма\n",
    "data = {'values_column': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Функция для вычисления суммы значений в куске датафрейма\n",
    "def calculate_sum(slice_df):\n",
    "    return slice_df['values_column'].sum()\n",
    "\n",
    "# Применяем функцию к каждой строке с учетом следующих 5 строк\n",
    "df['sum_next_5'] = df.apply(lambda row: calculate_sum(df.loc[row.name:row.name+1]), axis=1)\n",
    "\n",
    "# Выводим полученный датафрейм\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   значение  разница_с_тремя_строками_ранее\n",
      "0        10                             NaN\n",
      "1        15                             NaN\n",
      "2        20                             NaN\n",
      "3        25                            15.0\n",
      "4        30                            15.0\n",
      "5        35                            15.0\n",
      "6        40                            15.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Создание примера DataFrame\n",
    "data = {'значение': [10, 15, 20, 25, 30, 35, 40]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Вычисление разницы между текущим значением и значением тремя строками ранее\n",
    "df['разница_с_тремя_строками_ранее'] = df['значение'].diff(periods=3)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib as smtp\n",
    "from getpass import getpass\n",
    "email = input('введите почту: \\n')\n",
    "password = getpass('введите пароль: ')\n",
    "dest_email = input('введите адрес получателя: \\n')\n",
    "subject = input('тема письма: \\n')\n",
    "email_text = input('текст письма: \\n' )\n",
    "message = 'From: {}\\nTo: {}\\nSubject: {}\\n\\n{}'.format(email,\n",
    "                                                       dest_email,\n",
    "                                                       subject,\n",
    "                                                       email_text)\n",
    "server = smtp.SMTP_SSL('smtp.yandex.com')\n",
    "server.set_debuglevel(1)\n",
    "server.ehlo(email)\n",
    "server.login(email, password)\n",
    "server.auth_plain()\n",
    "server.sendmail(email, dest_email, message)\n",
    "server.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3928f246a083475ced1efabd59546987b0916536de4a1f794c4949e18b9c171"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
